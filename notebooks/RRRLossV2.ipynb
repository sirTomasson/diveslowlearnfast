{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RRRLossV2\n",
    "This notebook contains some improvements that hopefully will stabilise the erratic behaviour of our original implementation."
   ],
   "id": "19c253509b7d237a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports & Initialisation",
   "id": "f4d621968b05d073"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:35:00.753574Z",
     "start_time": "2025-04-23T08:34:57.227816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import diveslowlearnfast as dlf\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from diveslowlearnfast.datasets import Diving48Dataset\n",
    "from diveslowlearnfast.egl.explainer import ExplainerStrategy\n",
    "from diveslowlearnfast.train.helper import get_test_transform\n",
    "from diveslowlearnfast.models import SlowFast, load_checkpoint\n",
    "from diveslowlearnfast.config import Config\n",
    "from diveslowlearnfast.visualise.gradcam import GradCAM\n",
    "from diveslowlearnfast.train import helper as train_helper, StatsDB\n",
    "from diveslowlearnfast.egl import helper as egl_helper\n",
    "\n",
    "cfg = Config()\n",
    "cfg.DATA.DATASET_PATH = '/Users/youritomassen/Projects/xai/data/Diving48/'\n",
    "cfg.TRAIN.BATCH_SIZE = 4\n",
    "cfg.GRADCAM.TARGET_LAYERS = ['s5/pathway0_res2', 's5/pathway0_res2']\n",
    "device = torch.device('cpu')\n",
    "model = SlowFast(cfg)\n",
    "_, optimiser, *_ = train_helper.get_train_objects(cfg, model)\n",
    "model, *_ = load_checkpoint(model, '../misc/checkpoint.pth', optimiser,  device)"
   ],
   "id": "f730e61062ffd57c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The `Code`\n",
    "These code changes were obtained by integrating the author's original implementation. **Note** this implementation has an additional gradient penalty which may be ignored. Key differences are calculating the gradients over the log probalities\n",
    "\n",
    "```python\n",
    "# RRRLoss by the original author\n",
    "def loss_function(self, l2_grads=1000, l1_grads=0, l2_params=0.0001):\n",
    "    right_answer_loss = tf.reduce_sum(tf.multiply(self.y, -self.log_prob_ys))\n",
    "\n",
    "    gradXes = tf.gradients(self.log_prob_ys, self.X)[0]\n",
    "    A_gradX = tf.multiply(self.A, gradXes)\n",
    "    right_reason_loss = 0\n",
    "    if l1_grads > 0:\n",
    "      right_reason_loss += l1_grads * tf.reduce_sum(tf.abs(A_gradX))\n",
    "    if l2_grads > 0:\n",
    "      right_reason_loss += l2_grads * tf.nn.l2_loss(A_gradX)\n",
    "\n",
    "    small_params_loss = l2_params * tf.add_n([tf.nn.l2_loss(p) for p in self.W + self.b])\n",
    "\n",
    "    return right_answer_loss + right_reason_loss + small_params_loss\n",
    "```"
   ],
   "id": "2c6ce979a4794908"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:37:43.907461Z",
     "start_time": "2025-04-23T08:37:43.835567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DualPathRRRLossV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 lambdas=None,\n",
    "                 normalise_gradients=False,\n",
    "                 skip_zero_masks=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if lambdas is None:\n",
    "            lambdas = [1000.0, 1000.0]\n",
    "\n",
    "        self.lambdas = lambdas\n",
    "        self.normalise_gradients = normalise_gradients\n",
    "        self.skip_zero_masks = skip_zero_masks\n",
    "\n",
    "    def forward(self, logits, targets, inputs, masks, warmup=False):\n",
    "        batch_size = logits.size(0)\n",
    "\n",
    "        # Convert targets to one-hot encoding for proper calculation\n",
    "        num_classes = logits.size(1)\n",
    "        target_one_hot = torch.zeros_like(logits).scatter_(1, targets.unsqueeze(1), 1)\n",
    "\n",
    "        # Calculate the log probabilities\n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "\n",
    "        # Calculate cross-entropy loss (right answer loss)\n",
    "        # This matches tf.reduce_sum(tf.multiply(self.y, -self.log_prob_ys))\n",
    "        right_answer_loss = -torch.sum(target_one_hot * log_probs) / batch_size\n",
    "\n",
    "        total_loss = right_answer_loss\n",
    "        losses = {'ce_loss': right_answer_loss.item()}\n",
    "\n",
    "        if warmup or (self.skip_zero_masks and all(torch.sum(mask) == 0 for mask in masks)):\n",
    "            losses['total_loss'] = total_loss.item()\n",
    "            for idx in range(len(inputs)):\n",
    "                losses[f'gradient_loss_path_{idx}'] = 0\n",
    "            return total_loss, losses\n",
    "\n",
    "        # Calculate gradient penalties for each input path\n",
    "        for idx, (inp, mask) in enumerate(zip(inputs, masks)):\n",
    "            if torch.sum(mask) == 0 and self.skip_zero_masks:\n",
    "                losses[f'gradient_loss_path_{idx}'] = 0\n",
    "                continue\n",
    "\n",
    "            # Calculate gradients of log_probs with respect to input\n",
    "            # This matches tf.gradients(self.log_prob_ys, self.X)[0]\n",
    "            gradients = torch.autograd.grad(\n",
    "                log_probs,\n",
    "                inp,\n",
    "                grad_outputs=torch.ones_like(log_probs),\n",
    "                create_graph=True,\n",
    "                retain_graph=True\n",
    "            )[0]\n",
    "\n",
    "            if self.normalise_gradients:\n",
    "                gradients = gradients / (torch.norm(gradients, dim=1, keepdim=True) + 1e-10)\n",
    "\n",
    "            # Apply mask to gradients (A_gradX = tf.multiply(self.A, gradXes))\n",
    "            masked_gradients = mask * gradients\n",
    "\n",
    "            # L2 gradient penalty (l2_grads * tf.nn.l2_loss(A_gradX))\n",
    "            n_frames = inp.size(2)\n",
    "            l2_grad_loss = self.lambdas[idx] * torch.sum(masked_gradients**2) / (batch_size * n_frames)\n",
    "\n",
    "\n",
    "            gradient_loss = l2_grad_loss\n",
    "            total_loss += gradient_loss\n",
    "\n",
    "            losses[f'gradient_loss_path_{idx}'] = gradient_loss.item()\n",
    "\n",
    "        losses['total_loss'] = total_loss.item()\n",
    "        return total_loss, losses"
   ],
   "id": "20740c138856cbeb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preparation",
   "id": "415548a6d5c1510e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:36:14.098364Z",
     "start_time": "2025-04-23T08:36:13.868656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cfg.EGL.MASKS_CACHE_DIR = './.masks'\n",
    "slow_masks_dir = os.path.join(cfg.EGL.MASKS_CACHE_DIR, 'slow')\n",
    "\n",
    "stats_db = StatsDB('./data/stats.db')\n",
    "difficult_samples = stats_db.get_below_median_samples(\n",
    "    epoch_start=90,\n",
    "    run_id='/home/s2871513/Projects/diveslowlearnfast/results/run18',\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "non_mask_video_ids = list(map(lambda x: x[0], difficult_samples))[:8]\n",
    "mask_npys = os.listdir(slow_masks_dir)\n",
    "masked_video_ids = list(map(lambda x: x.replace('.npy', ''), mask_npys))[:8]\n",
    "mixed_video_ids = masked_video_ids[:1] + non_mask_video_ids[:7]\n",
    "\n",
    "\n",
    "def get_batch(video_ids=None):\n",
    "    cfg.DATA.TEST_CROP_SIZE = 224\n",
    "    dataset = Diving48Dataset(\n",
    "        cfg.DATA.DATASET_PATH,\n",
    "        cfg.DATA.NUM_FRAMES,\n",
    "        alpha=cfg.SLOWFAST.ALPHA,\n",
    "        dataset_type='train',\n",
    "        transform_fn=get_test_transform(cfg),  # use test_transform instead\n",
    "        use_decord=cfg.DATA_LOADER.USE_DECORD,\n",
    "        temporal_random_jitter=cfg.DATA.TEMPORAL_RANDOM_JITTER,\n",
    "        temporal_random_offset=cfg.DATA.TEMPORAL_RANDOM_OFFSET,\n",
    "        multi_thread_decode=cfg.DATA.MULTI_THREAD_DECODE,\n",
    "        threshold=cfg.DATA.THRESHOLD,\n",
    "        use_sampling_ratio=cfg.DATA.USE_SAMPLING_RATIO,\n",
    "        video_ids=video_ids,\n",
    "        mask_type='gradcam',\n",
    "        masks_cache_dir=cfg.EGL.MASKS_CACHE_DIR,\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=8,\n",
    "        pin_memory=cfg.DATA_LOADER.PIN_MEMORY,\n",
    "        num_workers=cfg.DATA_LOADER.NUM_WORKERS,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return next(iter(loader))\n",
    "\n",
    "\n",
    "non_mask_video_ids, masked_video_ids, mixed_video_ids"
   ],
   "id": "1298a2097ee5fde4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['3N1kUtqJ25A_00065',\n",
       "  '3N1kUtqJ25A_00185',\n",
       "  '3PLiUG_DuC8_00167',\n",
       "  '9BC6ssCjyfg_00232',\n",
       "  '9jZYYtzYqwE_00081',\n",
       "  'Bb0ZiYVNtDs_00072',\n",
       "  'D6zILEKIJbk_00190',\n",
       "  'JzOshOJgofw_00022'],\n",
       " ['JzOshOJgofw_00176',\n",
       "  'nOlRwoxsDJ0_00609',\n",
       "  'db7DmpqzGmc_00121',\n",
       "  'RWNrARSbRCY_00021',\n",
       "  'iv0Gu1VXAgc_00067',\n",
       "  'fohMq9tOn6E_00135',\n",
       "  'JzOshOJgofw_00006',\n",
       "  'uDESPUxbjnI_00186'],\n",
       " ['JzOshOJgofw_00176',\n",
       "  '3N1kUtqJ25A_00065',\n",
       "  '3N1kUtqJ25A_00185',\n",
       "  '3PLiUG_DuC8_00167',\n",
       "  '9BC6ssCjyfg_00232',\n",
       "  '9jZYYtzYqwE_00081',\n",
       "  'Bb0ZiYVNtDs_00072',\n",
       "  'D6zILEKIJbk_00190'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:36:26.935597Z",
     "start_time": "2025-04-23T08:36:15.767663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xb, yb, _, _, _, mslow, mfast = get_batch(video_ids=masked_video_ids)\n",
    "xb.shape, yb.shape, mslow.shape, mfast.shape"
   ],
   "id": "4a4cfb9e1da62e92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 32, 224, 224]),\n",
       " torch.Size([8]),\n",
       " torch.Size([8, 1, 4, 224, 224]),\n",
       " torch.Size([8, 1, 32, 224, 224]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:36:41.510395Z",
     "start_time": "2025-04-23T08:36:33.829443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = dlf.to_slowfast_inputs(xb, alpha=cfg.SLOWFAST.ALPHA, requires_grad=True)\n",
    "logits = model(inputs)\n",
    "nn.CrossEntropyLoss()(logits, yb)"
   ],
   "id": "5e4eb6dcbda7363c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0366, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:38:06.685251Z",
     "start_time": "2025-04-23T08:37:46.520093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = DualPathRRRLossV2(lambdas=[.01, .01])\n",
    "total_loss, all_losses = criterion(logits, yb, inputs, [mslow, mfast])\n",
    "total_loss, all_losses"
   ],
   "id": "2ff8e5d2713b7f9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2.4581, grad_fn=<AddBackward0>),\n",
       " {'ce_loss': 0.036621104925870895,\n",
       "  'gradient_loss_path_0': 1.0924240350723267,\n",
       "  'gradient_loss_path_1': 1.3290122747421265,\n",
       "  'total_loss': 2.458057403564453})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T14:36:29.455471Z",
     "start_time": "2025-04-22T14:36:29.384693Z"
    }
   },
   "cell_type": "code",
   "source": "all_losses",
   "id": "c7a39f60eed7a046",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ce_loss': 1.531362771987915,\n",
       " 'gradient_loss_path_0': 351848.9375,\n",
       " 'gradient_loss_path_1': 2585570.75,\n",
       " 'total_loss': 2937421.25}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
