{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T12:40:05.184382Z",
     "start_time": "2025-02-11T12:40:04.091350Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from diveslowlearnfast.datasets import Diving48Dataset\n",
    "from diveslowlearnfast.egl.explainer import ExplainerStrategy\n",
    "from diveslowlearnfast.train.helper import get_test_transform\n",
    "from diveslowlearnfast.models import SlowFast, load_checkpoint\n",
    "from diveslowlearnfast.config import Config\n",
    "from diveslowlearnfast.visualise.gradcam import GradCAM\n",
    "from diveslowlearnfast.train import helper as train_helper, StatsDB\n",
    "from diveslowlearnfast.egl import helper as egl_helper\n",
    "from diveslowlearnfast.loss.rrr import RRRLoss\n",
    "\n",
    "cfg = Config()\n",
    "cfg.DATA.DATASET_PATH = '/Users/youritomassen/Projects/xai/data/Diving48/'\n",
    "cfg.TRAIN.BATCH_SIZE = 4\n",
    "cfg.GRADCAM.TARGET_LAYERS = ['s5/pathway0_res2', 's5/pathway0_res2']\n",
    "device = torch.device('cpu')\n",
    "model = SlowFast(cfg)\n",
    "_, optimiser, *_ = train_helper.get_train_objects(cfg, model)\n",
    "model, *_ = load_checkpoint(model, optimiser, '../misc/checkpoint.pth', device)\n",
    "explainer = ExplainerStrategy.get_explainer(model, cfg=cfg, device=device)\n",
    "\n",
    "train_dataset = Diving48Dataset(\n",
    "    cfg.DATA.DATASET_PATH,\n",
    "    cfg.DATA.NUM_FRAMES,\n",
    "    dataset_type='train',\n",
    "    transform_fn=get_test_transform(cfg),  # use test_transform instead\n",
    "    use_decord=cfg.DATA_LOADER.USE_DECORD,\n",
    "    temporal_random_jitter=cfg.DATA.TEMPORAL_RANDOM_JITTER,\n",
    "    temporal_random_offset=cfg.DATA.TEMPORAL_RANDOM_OFFSET,\n",
    "    multi_thread_decode=cfg.DATA.MULTI_THREAD_DECODE,\n",
    "    threshold=cfg.DATA.THRESHOLD,\n",
    "    use_dynamic_temporal_stride=cfg.DATA.USE_DYNAMIC_TEMPORAL_STRIDE,\n",
    "    masks_cache_dir='../results/run11/.masks'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "    pin_memory=cfg.DATA_LOADER.PIN_MEMORY,\n",
    "    num_workers=cfg.DATA_LOADER.NUM_WORKERS,\n",
    "    shuffle=True,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:32:37.753673Z",
     "start_time": "2025-02-11T13:31:58.435568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xb, yb, _, _, _, masks = next(iter(train_loader))\n",
    "masks[0, :, :, :, :] = 1"
   ],
   "id": "941e8d5b3e7380ca",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:32:00.119466Z",
     "start_time": "2025-02-11T11:32:00.092994Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = RRRLoss()",
   "id": "a62568c0f76a8d8b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:22:56.089339Z",
     "start_time": "2025-02-11T13:22:51.869693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xb_fast = xb[:].to(device)\n",
    "# reduce the number of frames by the alpha ratio\n",
    "# B x C x T / alpha x H x W\n",
    "xb_slow = xb[:, :, ::cfg.SLOWFAST.ALPHA].to(device)\n",
    "xb_fast.requires_grad = True\n",
    "logits = model([xb_slow, xb_fast])"
   ],
   "id": "e265ecdfdb325a75",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T12:51:33.128249Z",
     "start_time": "2025-02-11T12:51:05.958094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss, loss_components = criterion(logits, yb, model, xb_fast, masks)\n",
    "start = time.time()\n",
    "loss.backward()\n",
    "print('backward took', time.time() - start)"
   ],
   "id": "7abf388867c01f4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss  0.0002338886260986328\n",
      "True\n",
      "log probs took  0.0002498626708984375\n",
      "gradients took 4.902899742126465\n",
      "backward took 22.167354822158813\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T11:39:03.713491Z",
     "start_time": "2025-02-11T11:39:03.685421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()"
   ],
   "id": "40c35bbefb092cff",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:23:02.786468Z",
     "start_time": "2025-02-11T13:22:57.376183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = ce_loss(logits, yb)\n",
    "start = time.time()\n",
    "loss.backward()\n",
    "print('backward took', time.time() - start)"
   ],
   "id": "f36ba0f8f28a9249",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward took 5.390617847442627\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:33:07.801332Z",
     "start_time": "2025-02-11T13:33:02.677771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xb_fast = xb[:].to(device)\n",
    "# reduce the number of frames by the alpha ratio\n",
    "# B x C x T / alpha x H x W\n",
    "xb_slow = xb[:, :, ::cfg.SLOWFAST.ALPHA].to(device)\n",
    "xb_fast.requires_grad = True\n",
    "logits = model([xb_slow, xb_fast])"
   ],
   "id": "459549ca4bb07939",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:34:46.205743Z",
     "start_time": "2025-02-11T13:34:46.186124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rrr(logits, targets, inputs, masks, cross_entropy):\n",
    "    \"\"\"\n",
    "    Compute the RRR loss.\n",
    "\n",
    "    Args:\n",
    "        logits: Model output logits (B x num_classes)\n",
    "        targets: Ground truth labels (B)\n",
    "        model: The model being trained\n",
    "        inputs: Input data (B x ...)\n",
    "        masks: Binary masks indicating where gradients should be small (B x ...)\n",
    "\n",
    "    Returns:\n",
    "        total_loss: Combined loss value\n",
    "        losses: Dictionary containing individual loss components\n",
    "    \"\"\"\n",
    "    ce_loss = cross_entropy(logits, targets)\n",
    "    # boolean mask to select indices for which there is a mask available\n",
    "    # this little optimisation ensures that we do not use autograd on inputs that will\n",
    "    # be ignored anyway\n",
    "    mask = (masks.sum(dim=(1, 2, 3, 4)) > 0)\n",
    "    masked_elements = inputs[mask]\n",
    "\n",
    "    if masked_elements.shape[0] > 0:\n",
    "        log_probs = F.softmax(masked_elements, dim=1)\n",
    "        summed_log_probs = log_probs.sum()\n",
    "        gradients = torch.autograd.grad(summed_log_probs, inputs, create_graph=True, retain_graph=True)[0]\n",
    "        gradient_loss = (masks * gradients).pow(2).mean()\n",
    "        gradient_loss_item = gradient_loss.item()\n",
    "    else:\n",
    "        gradient_loss = 0\n",
    "        gradient_loss_item = gradient_loss\n",
    "\n",
    "    total_loss = ce_loss + 1000.0 * gradient_loss\n",
    "\n",
    "    losses = {\n",
    "        'total_loss': total_loss.item(),\n",
    "        'ce_loss': ce_loss.item(),\n",
    "        'gradient_loss': gradient_loss_item\n",
    "    }\n",
    "\n",
    "    return total_loss, losses"
   ],
   "id": "d1ab565764d7a901",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T13:34:54.878764Z",
     "start_time": "2025-02-11T13:34:47.216439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('masks count =', (masks.sum(dim=(1, 2, 3, 4)) > 0).sum().item())\n",
    "loss, all_losses = rrr(logits, yb, xb_fast, masks, nn.CrossEntropyLoss())\n",
    "start = time.time()\n",
    "loss.backward()\n",
    "print('backward took', time.time() - start)"
   ],
   "id": "9ca48c2293f29dc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks count= 1\n",
      "backward took 7.548271179199219\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a03eee3339bf7705"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
